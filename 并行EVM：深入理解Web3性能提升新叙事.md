# 并行EVM：深入理解Web3性能提升新叙事

## TL;DR

## 1. 行业综述

### 1.1 历史沿革

区块链网络为个人和企业进行交易创造了一种新的、去中心化的信任基础。以比特币为代表的第一代区块链网络以分布式记账的方式开创了去中心化的电子货币交易新模式，革命性地开创了一个新时代。随后，以以太坊为代表的第二代区块链网络则充分发挥想象力，提出以分布式状态机的方式实现去中心化应用（dApp）。从那时起，区块链网络开启了它自己十几年飞速发展的历史，从Web3基础设施到以DeFi、NFT、社交网络和GameFi等为代表的各种赛道，诞生了无数或技术或商业模式的创新。行业的蓬勃发展需要不断吸引新用户参与去中心化应用的生态建设，吸引新用户反过来又对产品体验提出了更高的要求。而Web3应用作为一种创新的产品形态，不但要在满足用户需要上有所创新（功能性需求），还要考虑怎样在安全性和性能之间取得平衡（非功能性需求）。自诞生以来，人们提出了各种各样的解决方案试图解决性能问题。这些解决方案大致可以分为两类：一类是链上扩容方案，如分片（sharding）和有向无环图（DAG）；一类是链下扩容方案，如Plasma、闪电网络、侧链和Rollups等。但这还远远跟不上链上交易快速增长的速度。

![](/Users/likejun/Desktop/TEAM-C/Gryphsis/ga-final-report/fig1-Ethereum Trans Count & Active Wallets.png)

尤其是经历了2020年DeFi Summer以及2023年年末比特币生态中铭文的持续爆发，业界迫切需要新的性能提升方案来满足“高性能、低费率”的要求。并行EVM的新叙事就是在这样的背景下诞生的。

### 1.2 市场规模

![](/Users/likejun/Desktop/TEAM-C/Gryphsis/ga-final-report/fig2-PEVM L1 projects.png)

目前并行EVM叙事才刚刚兴起，相关叙事的项目还不多，还处于比较早期的阶段。但少数项目如Solana、Aptos和Sui眼光独到，早在另起炉灶时就提前布局了链的并行执行能力，并得到了很好的发展，代币流通市值分别达到450亿、33亿和19亿美元。Sei在其v2版本升级提案中高调宣称将成为[第一个并行EVM区块链](https://blog.sei.io/sei-v2-the-first-parallelized-evm/)，预后还有更大的发展。与其同时当下营销热度第一的并行EVM新公链Monad潜力也不可小视。几乎所有的项目都进行了不同轮次的融资活动。坊间传言Lumio近期也将公布其融资情况。从各大投资公司真金白银的用钱投票来看，并行EVM赛道值得持续关注。

![](/Users/likejun/Desktop/TEAM-C/Gryphsis/ga-final-report/fig3-PEVM vs Ethereum Ecosystems & L1.png)

总的来看，并行EVM主要项目目前代币流通市值约为523.69亿美元，24小时交易量约为31.029亿美元。其中L1项目占比最大，其代币流通市值为523亿美元，24小时交易量为31亿美元，相比之下L2项目还在早期阶段，缺少相关数据，可忽略不计。而当前EVM生态总市值约为3900亿美元，24小时交易量约为342亿美元。L1生态代币流通市值为5730亿美元，24小时交易量为288亿美元。无论是总体上与以太坊生态进行比较，还是单独观察L1项目与整个L1生态，并行EVM叙事都有很大的成长空间。而且随着进一步的发展，相信会有更多L2项目不断涌现。

###1.3 行业图谱

业界一般将区块链网络分为4层结构：

1. **Layer 0（网络）**：区块链底层网络，处理基础的网络通信协议
2. **Layer 1（基础设施）**：依赖各种共识机制对交易进行验证的去中心化网络
3. **Layer 2（扩展）**：依赖于Layer 1的各种二层协议，旨在解决Layer 1的各种局限性，尤其是可扩展性
4. **Layer 3（应用）**：依赖于Layer 2或Layer 1，用于构建各种去中心化应用（dApp）

![](/Users/likejun/Desktop/TEAM-C/Gryphsis/ga-final-report/fig4-EVM&PEVML1.png)

作为一种比较底层的技术迭代，**并行EVM叙事主要分为L1和L2两派**。一派自建L1，成为自带并行交易处理能力的新公链，**争当高性能基础设施**。另一派成为L2，通过整合其他链的能力进行扩容，**其共同的特点在于跨生态合作**。L1这一派中，以Monad和Sei v2为代表的项目自行设计并行EVM，兼容以太坊生态并提供更快速的交易处理能力。以Solana、Aptos和Sui为代表的项目则另起炉灶，成为以太坊强有力的竞争者。L2这一派中，Neon是基于Solana的EVM网络，Eclipse是可定制的模块化rollups，二者均属于Solana生态的基础设施项目。Lumio则利用Aptos执行交易并利用以太坊作为结算层，是Aptos生态中的基础设施项目。

从项目总数和几个主要赛道的发展可以看出，比起以太坊，各L1公链生态仍然存在很大的发展空间。随着版本的升级和兼容EVM的并行新公链的出现，以太坊生态本身也会得到进一步的发展。伴随着基础设施的不断完善，非EVM公链未来也会涌现出更多对并行处理能力要求更高的项目。此类项目最容易出现在对“高速低费率”有要求的DeFi领域，以及对“强实时交互”有要求的游戏领域。而并行EVM叙事必然会给这些项目带来更好的用户体验，推动行业的发展进入到全新的阶段。

![](/Users/likejun/Desktop/TEAM-C/Gryphsis/ga-final-report/fig5-Fuel Ecosystems.png)

在上述单体区块链解决方案之外，Fuel提出了自己的模块化区块链思路。它将在第二个版本中将自己定位成**未来更灵活、更彻底的模块化执行层**。Fuel专注于执行交易，而将其余部分外包给一个或多个独立层的区块链，从而实现更灵活的组合：既可以成为 L2，也可以成为 L1，甚至是侧链或状态通道。目前Fuel生态有17个项目，主要集中在DeFi、NFT和基础设施三个领域。不过只有Orally跨链预言机已投入实际应用。去中心化借贷平台Swaylend和永续合约交易平台SPARK上了测试网，其他项目还在开发中。

### 1.4 技术实现路径

要实现去中心化的交易执行，区块链网络必须履行4个职责：

* 执行：执行和验证交易
* 数据可用性：分发新区块到区块网络的所有节点
* 共识机制：验证区块，达成共识
* 结算：结算并记录交易的最终状态

**并行EVM叙事本质上是对区块链执行层的性能优化**。这又分为一层网络（L1）解决方案和二层网络（L2）解决方案两种。L1的解决方案本质上是引入并行执行机制，让区块链虚拟机的执行并行化。L2的解决方案本质上是利用已经并行化的L1虚拟机实现某种程度上的“链下执行+链上结算”，这与Rollup机制异曲同工。所以要理解并行EVM的工作原理，就要将其拆解开来：先理解什么是虚拟机（virtual machine）再理解什么是并行执行（parallel execution）。

#### 1.4.1 虚拟机

在计算机科学中，虚拟机是指对计算机系统进行的虚拟（virtualization）或者模拟（emulation）。虚拟机分为两种，一种叫系统虚拟机（system virtual machine），可以将一台物理机虚拟化为多台机器，运行多个操作系统，从而提高资源利用率。另一种叫进程虚拟机（process virtual machine），为某些高级编程语言提供抽象，让使用这种语言编写的计算机程序以一种平台无关的方式运行在不同平台上。JVM就是一种为Java编程语言设计的进程虚拟机。Java语言编写的程序首先被编译成Java字节码（一种中间状态的二进制代码），Java字节码由JVM解释执行：JVM将字节码送给解释器，由解释器翻译成不同机器上的机器码，然后在机器上运行。

区块链虚拟机是进程虚拟机的一种。在区块链的语境下，虚拟机是指对分布式状态机进行的虚拟，用于分布式地执行合约，运行dApp。类比JVM，EVM就是一种为Solidity语言设计的进程虚拟机，智能合约首先被编译成opcode字节码，然后由EVM解释执行。

以太坊之外的新兴公链在实现自己的虚拟机时，更多采用的是基于wasm或eBPF字节码的虚拟机。WASM是一种体积小、加载快、可移植且基于沙盒安全机制的字节码格式，开发人员可以使用多种编程语言（C、C++、Rust、Go、Python、Java甚至TypeScript等）编写智能合约，然后编译成wasm字节码并执行。Sei公链上执行的智能合约正是采用了这一字节码格式。

eBPF前身是BPF（Berkeley Packet Filter，伯克利包过滤器），原本是用于网络数据包的高效过滤，后经过演化形成了eBPF，提供更丰富的指令集。它是一项允许在不改动源码的情况下对操作系统内核进行动态干预和修改其行为的革命性技术。后来这项技术从内核中走出来，发展出了用户态eBPF运行时，其具有高性能、安全和可移植性。在Solana上执行的智能合约都会编译成eBPF字节码并在其区块链网络上运行。

而其他的L1公链中，Aptos和Sui使用Move智能合约编程语言，编译成特有的字节码在Move虚拟机上执行。Monad则自行设计了兼容EVM opcode字节码（Shanghai fork）的虚拟机。

![](/Users/likejun/Desktop/TEAM-C/Gryphsis/ga-final-report/fig6-virtual machine.png)

#### 1.4.2 并行执行

并行执行就是尽可能地发挥多核处理器的优势同时处理多个任务，增大系统的吞吐量。区块链网络常用tps（每秒处理的交易数量）作为衡量交易处理速度的技术指标。并行执行的机制比较复杂，也很考验开发人员的技术水平，要解释清楚并不容易。这里从一个简单的例子入手：我们把系统看成一家银行，把处理任务的CPU看成柜台，那么线性地执行任务就好比这家银行只有一个柜台受理业务。此时来银行办业务的客户（任务）只能排成一条长龙，挨个办业务。对于每个客户，柜台工作人员都要重复同样的动作（执行指令）来为客户办理业务。没有轮到自己时客户只能等待，这就造成交易时间的延长。此时银行看到人满为患，就多开了几个柜台来处理业务，有4个柜台同时处理业务，**理论上**速度就比原来快了4倍，那么客户排队的时间也减少到了原来的1/4，银行办理业务的速度就提升。

但是并行执行并没有它看上去的那么简单。有很多很微妙的细节，稍不注意就会导致非常严重的错误。比如有A、B和C三个人，他们的账户上分别有2ETH、1ETH和0ETH。现在A和B分别要给C转账0.5ETH。在一个交易顺序执行的系统中，过程如下（<=表示读取账本，=>表示写入账本，下同）：

| 步骤 |   A    |   B    |    C    | 备注                                                     |
| :--: | :----: | :----: | :-----: | :------------------------------------------------------- |
|  1   |  <= 2  |   /    |  <= 0   | 任务1：从账本中读取A的账户余额和C的账户余额              |
|  2   | 2-0.5  |   /    |  0+0.5  | 任务1：计算收支平衡：A账户余额减去0.5，C账户余额增加0.5  |
|  3   | => 1.5 |   /    | => 0.5  | 任务1：将A和C的账户余额更新回账本                        |
|  4   |   /    |  <= 1  | <= 0.5  | 任务2：从账本中读取B的账户余额和C的账户余额              |
|  5   |   /    | 1-0.5  | 0.5+0.5 | 任务2：计算收支平衡：B账户余额减去0.5，C账户余额增加 0.5 |
|  6   |   /    | => 0.5 |  => 1   | 任务2：将B和C的账户余额更新回账本                        |

如果A和B对C的转账交易是并行执行的，那么根据每个步骤执行先后顺序的不同，就有可能产生不一致的结果：

| 步骤 |   A    |   B    |   C    | 备注                                                        |
| :--: | :----: | :----: | :----: | ----------------------------------------------------------- |
|  1   |  <= 2  |   /    |  <= 0  | 并行任务1：从账本中读取A和C的账户余额                       |
|  2   | 2-0.5  |   /    | 0+0.5  | 并行任务1：计算收支平衡，A账户余额减去0.5，C账户余额增加0.5 |
|  *3  |   /    |  <= 1  |  <= 0  | 并行任务2：从账本中读取B和C的账户余额（注意，还是0！）      |
|  4   | => 1.5 |   /    | => 0.5 | 并行任务1：将A和C的账户余额更新回账本                       |
|  *5  |   /    | 1-0.5  | 0+0.5  | 并行任务2：计算收支平衡，B账户余额减去0.5，C账户余额增加0.5 |
|  *6  |   /    | => 0.5 | => 0.5 | 并行任务2：将B和C的账户余额更新回账本                       |

并行任务1执行A到C的转账，并行任务2执行B到C的转账，表中带*号的步骤都是有问题的：由于任务是并行执行的，在步骤2中并行任务1做的收支平衡计算还没来得及写入账本，在步骤3中任务2就把C的账户余额（此时仍然是0）读取出来了，并在步骤5中基于余额0做了错误的收支平衡计算，然后在步骤6的账本更新操作中把步骤4中已经更新的账户余额0.5错误地再次更新成了0.5。导致虽然A和B都同时转账了0.5ETH给C，而交易执行完毕后C的账户余额却只有0.5ETH，另外0.5ETH不翼而飞了。

现在让我们并行执行两个任务：并行任务1执行A（余额2ETH）转账0.5ETH给C（余额0ETH），并行任务2执行B（余额1ETH）转账0.5ETH到D（余额0ETH）。那么不管两个任务的步骤如何交错执行，都不会有上面的问题：

| 步骤 |   A    |   B    |   C    |   D    | 备注                                                        |
| ---- | :----: | :----: | :----: | :----: | ----------------------------------------------------------- |
| 1    |  <= 2  |   /    |  <= 0  |   /    | 并行任务1：从账本中读取A和C的账户余额                       |
| 2    |   /    |  <= 1  |   /    |  <= 0  | 并行任务2：从账本中读取B和D的账户余额                       |
| 3    | 2-0.5  |   /    | 0+0.5  |   /    | 并行任务1：计算收支平衡，A账户余额减去0.5，C账户余额增加0.5 |
| 4    |   /    | 1-0.5  |   /    | 0+0.5  | 并行任务2：计算收支平衡，B账户余额减去0.5，D账户余额增加0.5 |
| 5    | => 1.5 |   /    | => 0.5 |   /    | 并行任务1：将A和C的账户余额更新回账本                       |
| 6    |   /    | => 0.5 |   /    | => 0.5 | 并行任务2：将B和D的账户余额更新回账本                       |

从两种场景的对比可以分析得出，只要任务之间存在**依赖**，并行执行时就有可能发生状态更新错误，反之则不会发生错误。满足以下2个条件之一，就称任务（交易）之间是有依赖关系的：

1. 一个任务写入的输出地址是另一个任务读取的输入地址；
2. 两个任务输出到同一个地址。

这并不是去中心化特有的。任何涉及到并行执行的场景都会因为多个有依赖的任务之间不受保护地访问共享资源（上面例子中的“账本”，计算机系统中的共享内存等）而出现数据不一致，称为**竞态条件问题（data races）**。业界在解决并行执行的竞态条件问题上提出了三种执行机制：**消息传递机制**、**共享内存机制**和**严格状态访问列表机制**。

#### 1.4.3 消息传递机制

回到上面银行那个例子，仍然假设银行有4个柜台同时为客户办理业务，现在给4个柜台的柜员每个人手里发一本专属账本，这个账本只有自己能修改。上面记录了自己所服务的客户的账户余额。每个柜员在为客户办理业务时，如果该客户的信息在自己的账本上能查到，那么就直接办理；否则就给别的柜员发消息告知客户要办理的业务，别的柜员在收到消息后再进行办理。

这就是消息传递模型的原理。**Actor模型**就是消息传递模型的一种，每一个负责处理交易的执行者都是一个actor（柜员），它们都有可以访问自己的私有数据（专属账本），如果要访问别人的私有数据，只能通过发消息来实现。

![](/Users/likejun/Desktop/TEAM-C/Gryphsis/ga-final-report/fig7-actor model.png)

Actor模型的优点在于每个actor都只能访问自己的私有数据，因此就不会出现竞态条件问题。它的缺点有2个，一是每个actor都只能串行地执行，在某些场景中并没有发挥并行优势（比如2号、3号和4号柜员同时发消息问1号柜员客户A的账户余额是多少，1号柜员在这样的模型中就只能一个一个的处理消息，而这本来是可以并行处理的）。二是没有一个全局的有关当前系统状态的信息，如果系统业务复杂，将很难定位和修复bug。

#### 1.4.4 共享内存机制

##### 1.4.4.1 内存锁模型

现在让我们假设银行只有一个大账本，上面记录了所有客户的账户余额。账本旁边只有一支签字笔可以用来修改账本。在这种场景下，4个柜员在办理业务时就看谁跑得快了：一个柜员抢先拿到签字笔（类比加锁）开始办理业务修改账本，其他3个柜员就只能等着。直到柜员用完将笔放下（类比解锁），其他3个柜员再去争夺签字笔的使用权，如此循环下去，这就是**内存锁模型（memory locks）**。内存锁就是让并行执行的任务在访问共享资源的时候做一个锁（lock）的操作，锁住之后对共享资源进行访问，此时别的任务要等待它修改完之后解锁（unlock）才能再次锁住并访问。进一步地又演化出了**读写锁（read-write lock）**机制，可以对共享资源加**读锁（read lock）**或者**写锁（write lock）**。区别是多个并行任务可以加多次读锁并读取共享资源数据，此时不允许修改；而写锁只能加一把，且加了之后连读都不允许。在解决竞态条件问题的同时实现最大化的并行。

![](/Users/likejun/Desktop/TEAM-C/Gryphsis/ga-final-report/fig8-memory lock.png)

Solana、Sui和Sei v1采用的就是基于内存锁的共享内存模型。这种机制看上去简单，但实现起来很复杂，很考验开发人员对多线程编程的驾驭能力。一个不小心，就会留下各种各样的bug：

1. 情况1：任务锁住共享资源，但在执行的过程中因出错崩溃退出，共享资源再也没法释放了；
2. 情况2：任务已经加锁，但是执行过程中因为各种复杂的业务逻辑嵌套出现二次加锁，导致自己等待自己。

内存锁模型最容易出现**死锁（dead lock）**、**活锁（live lock）**和**饥饿（starvation）**等问题：（1）多个并行任务争夺多个共享资源，每个任务都占有了其中的一部分，都在等待对方释放资源，就会出现死锁问题；（2）并行任务检测发现还有其他并行任务处于活跃状态，于是主动让出自己占有的共享资源，导致你让过来我让过去，发生活锁；（3）优先级高的并行任务总是能获得共享资源访问权，其他低优先级任务长时间等待，发生“饥饿”。

![](/Users/likejun/Desktop/TEAM-C/Gryphsis/ga-final-report/fig9-dead live starvation.png)

##### 1.4.4.2 乐观并行化

乐观并行化的核心思想是**先假设所有的任务都是相互独立的**。先并行执行任务，然后再验证每个任务，如果验证不通过，则把这个任务重新执行一遍，直到所有任务执行完毕。还是以银行举例，这次4个柜员每个人在办理业务时都可以独立查阅和修改账本，而不管别的柜员在没在用账本。柜员使用账本时会记录自己查阅和修改了哪些内容。每次办完业务后都会再拿着账本和自己的记录对比一下，如果发现对不上，说明同一时间还有别的柜员也在使用账本，并且修改了相同的内容，本次业务就要作废并重新办理。这就是**乐观并行化**的基本原理。

![](/Users/likejun/Desktop/TEAM-C/Gryphsis/ga-final-report/fig10-optimistic concurrency.png)

假设有8个并行任务以乐观并行化的方式执行，期间需要访问2个共享资源。阶段1执行时，任务1、任务2和任务3并行执行。但任务2和任务3同时访问共享资源B产生了冲突，因此任务3在下一阶段重新调度执行。阶段2执行时任务3和任务4同时访问了共享资源B，此时任务4重新调度执行，以此类推，直到所有任务执行完毕。可以看到整个过程中发生冲突的任务会不断地重复执行。

乐观并行化模型采用了一种**多版本的内存中数据结构（multi-version in-memory data structure）**用来记录每一个写入值及其版本信息。每个并行任务的运行分为两个阶段：执行（execution）和验证（validation）。执行阶段会把所有读数据和写数据的行为记录下来，形成读集（read set）和写集（write set）。验证阶段会用读集和写集与多版本数据结构进行对比，如果对比发现不是最新的，则验证不通过。

乐观并行化模型发端于**软件事务内存（Software Transaction Memory，简称STM）**，后者是数据库领域无锁编程的一种机制。由于区块链网络对交易的处理天然的具备一种确定的顺序，因此这一思想被引入并演化出了Block-STM机制。Aptos和Monad采用了Block-STM作为自己的并行执行机制。值得一提的是，Sei公链在即将发布的v2版本中弃用了原来的内存锁模型，改为采用乐观并行化模型。Block-STM执行速度极快，实验环境中Aptos交易执行速度达到了惊人的160k tps，比顺序执行交易快了18倍。不光如此，dApp的开发者还可以像写顺序执行的程序一样编写智能合约，毫无心智负担。但底层公链必须完全实现Block-STM的复杂并行执行机制，这非常考验技术能力，因此压力给到了核心团队。

#### 1.4.5 严格状态访问列表

消息传递和共享内存机制是基于**账户/余额**数据模型实现的，它记录了每个链上账户的余额信息。就好比银行的账本中记录的是客户A有余额1000元，客户B有余额600元，每次处理交易只需要修改一下账户余额状态。如果换一种思路，还可以在每次交易时只记录交易的具体内容，形成交易流水，也能通过交易流水来计算用户的账户余额，例如有如下的交易流水：

1. 客户A开户并存入1000元；
2. 客户B开户（0元）；
3. 客户A向客户B转账100元。

通过读取流水并进行计算，可以知道当前客户A账户余额为900元；客户B账户余额为100元。**UTXO（unspent tx output，未花费的交易输出）**就类似这样的交易流水数据模型，它是第一代区块链比特币用来表示数字货币的一种方式。每一笔交易都有输入（怎么获得的）和输出（怎么花掉的），而UTXO可以简单理解为还没有花掉的收款。比如客户A有6个BTC，他给客户B转账5.2个BTC，还剩0.8个BTC，从UTXO的角度就可以看成：A的6个价值1BTC的UTXO被销毁，B获得了1个价值为5.2BTC的新生成的UTXO，同时找零给A一个价值0.8BTC的新生成的UTXO。即6个UTXO被销毁，生成了2个新的UTXO。

交易的输入和输出串成链，并使用数字签名记录所有权信息，就形成了UTXO模型。采取这种数据模型的区块链需要对某个账户地址的所有UTXO求和，才能知道当前账户余额。**严格状态访问列表机制（strict state access list）**基于UTXO模型实现并行执行。它会提前计算每个交易要访问的账户地址，形成访问列表。访问列表有两个作用：（1）交易执行时如果访问了不在访问列表中的地址，执行失败。（2）根据访问列表形成交易的多个集合，每个交易集合之间在访问列表上没有交集（没有依赖），因此多个交易集合就可以并行执行了。

![](/Users/likejun/Desktop/TEAM-C/Gryphsis/ga-final-report/fig11-fuel network.png)

Fuel就基于这样的机制实现了强大的并行执行能力。其愿景就是作为“速度最快的模块化区块链执行层”提供强大的计算能力。作为一站式Rollup解决方案，Fuel由虚拟机（FuelVM）、区块链开发语言（Sway）和发布并启动dApp的工具链组成。Fuel的核心理念为**以太坊上的Rollup操作系统**，它可以很好与L1公链的特性相结合，为以太坊生态赋能。

###1.5 行业增长驱动力

从内在规律上看，任何事物的发展都会经历”从无到有“到”从有到优“的过程，人类对更快速度的追求是永恒的。为解决区块网络执行速度的问题，人们进行了各种各样的尝试，诞生了各种各样或链上或链下的解决思路。并行EVM叙事就是其中一种技术上的探索。

从历史背景上看，随着SEC批准现货比特币ETF和即将发生的比特币减半等事件，再叠加美联储可能的降息操作，加密货币预期将迎来一段大牛市，行业的蓬勃发展需要更大吞吐量的区块链网络基础设施作为坚实的基础。

从资源管理上看，传统的区块网络是线性地处理交易的，这种处理方法虽然简单，但也是对处理器资源的一种浪费。而并行EVM实现了计算资源的物尽其用，充分”榨干“了多核处理器的性能，提高了区块网络的整体效能。

从行业的发展上看，虽然各种技术和商业模式的创新层出不穷，但Web3的成长潜力仍然有待挖掘。中心化网络能做到每秒推送50000多条消息、发送340万封邮件、完成100000次谷歌搜索并让成千上万个玩家同时在线。去中心化要与中心化分庭抗礼，拿下属于自己的半壁江山，不断优化并行执行机制，提高交易的吞吐量也是发展的必经之路。

从去中心化应用的发展上看，要吸引更多用户，体验上一定要下功夫。性能优化是提升用户体验的方向之一。对于DeFi用户来说，要满足高交易速度，低费率的需求。对于GameFi用户来说，要满足实时交互的需求。这些都需要并行执行作为支撑。未来无论什么赛道，去中心化应用一定是“功能需求+性能需求+经济模型”三位一体的。

## 2 标的梳理

Solana的SeaLevel技术

Sui的对象内存模型

Monad静态代码分析

Neon：运行在Solana虚拟机上的EVM模拟器

Eclipse：SVM执行，EVM结算

Lumio：双虚拟机支持

Fuel：基于UTXO模型的并行处理

## 3 结论与展望

从某种程度上来说，信息技术的发展史就是资源管理的发展史……操作系统就是一种管理硬件资源的基础软件，包括计算资源、存储资源和网络资源。在基础科学还没有发生革命性突破的当下，应用研究一定会在客观条件允许的范围内最大限度地进行各方面的探索。在并行EVM叙事之后，同样作为区块网络基础软件的基础设施赛道还会诞生与存储或网络有关的新叙事，让我们拭目以待。





